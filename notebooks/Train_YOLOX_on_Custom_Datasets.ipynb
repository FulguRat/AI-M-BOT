{"nbformat":4,"nbformat_minor":2,"metadata":{"accelerator":"GPU","colab":{"name":"Train_YOLOX_on_a_Custom_Dataset.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# How to Train YOLOX on Custom Objects\n","\n","This tutorial is based on the [YOLOX repository](https://github.com/Megvii-BaseDetection/YOLOX) by [the Megvii Team](https://github.com/Megvii-BaseDetection). This notebook shows training on **your own custom objects**. Many thanks to the Megvii Team for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n","\n","### Accompanying Blog Post\n","\n","We recommend that you follow along in this notebook while reading the blog post on [How to Train YOLOX](blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/), concurrently.\n","\n","### Steps Covered in this Tutorial\n","\n","In this tutorial, we will walk through the steps required to train YOLOR on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data. We will use Roboflow to preprocess our images.\n","\n","To train our detector we take the following steps:\n","\n","* Install YOLOX dependencies\n","* Download and Prepare custom YOLOX object detection data\n","* Download Pre-Trained Weights for YOLOX\n","* Run YOLOX training\n","* Evaluate YOLOX performance\n","* Run YOLOX inference on test images\n","* Export saved YOLOX weights for future inference\n","\n","### **About**\n","\n","[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n","\n","**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n","\n","![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"],"metadata":{"id":"Xru6s6p6A18s"}},{"cell_type":"markdown","source":["# Install YOLOX Dependencies"],"metadata":{"id":"VfVlxlYYBR6z"}},{"cell_type":"code","execution_count":null,"source":["# Change the current working directory\r\n","!pwd\r\n","!nvidia-smi\r\n","%cd SwitchFrequencyAnalysis"],"outputs":[],"metadata":{"id":"L8MWVu04xeef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632175093416,"user_tz":240,"elapsed":792,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}},"outputId":"7c7bf5eb-2f31-4749-dc46-00c32ebd3dda"}},{"cell_type":"code","execution_count":null,"source":["!git clone https://github.com/JiaPai12138/YOLOX.git\r\n","%cd YOLOX\r\n","!pip3 install -U pip && pip3 install -r requirements.txt\r\n","!pip3 install -v -e .  \r\n","!pip uninstall -y torch torchvision torchaudio\r\n","!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"],"outputs":[],"metadata":{"id":"igwruhYxE_a7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632175448096,"user_tz":240,"elapsed":350857,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}},"outputId":"b8868a13-b901-4b8b-f355-af63557de1fe"}},{"cell_type":"markdown","source":["## Install Nvidia Apex"],"metadata":{"id":"llsu3xhVBZYC"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/\r\n","!git clone https://github.com/NVIDIA/apex\r\n","%cd apex\r\n","!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"outputs":[],"metadata":{"id":"ksHd57LFFMzK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632175934918,"user_tz":240,"elapsed":448252,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}},"outputId":"e86e0ade-a3cf-4695-b525-0b53ddae02ce"}},{"cell_type":"markdown","source":["## Install PyCocoTools"],"metadata":{"id":"oc-EidleBfeB"}},{"cell_type":"code","execution_count":null,"source":["!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"],"outputs":[],"metadata":{"id":"JwuWoBOxFV6v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632176024173,"user_tz":240,"elapsed":14729,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}},"outputId":"60a049bc-bcb3-4391-c064-b5de21f55809"}},{"cell_type":"markdown","source":["# Export Trained Weights for Future Inference\n","\n","Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"],"metadata":{"id":"XFbMKDkxPWoD"}},{"cell_type":"code","execution_count":null,"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"outputs":[],"metadata":{"id":"SlZf3KlMPYPS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632176052079,"user_tz":240,"elapsed":23454,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}},"outputId":"e862bd3f-0bff-4480-ba1a-898508a473aa"}},{"cell_type":"code","execution_count":null,"source":["# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\r\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\r\n","\r\n","# list contents in yolo folder in your drive\r\n","!ls /mydrive/yolox"],"outputs":[],"metadata":{"id":"LDrqgjePPaXK","executionInfo":{"status":"ok","timestamp":1632176055157,"user_tz":240,"elapsed":1042,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}}}},{"cell_type":"markdown","source":["# Download or copy your Data\r\n","\r\n","We'll download our dataset from Roboflow. Use the \"**Pascal VOC**\" export format.\r\n","\r\n","To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\r\n"],"metadata":{"id":"UEdiT0rJBmRA"}},{"cell_type":"code","execution_count":null,"source":["%cd SwitchFrequencyAnalysis\r\n","#%cd /content/\r\n","#!curl -L \"[YOUR LINK HERE]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\r\n","\r\n","#%cd YOLOX/\r\n","\r\n","#!ln -s /content/train/ ./datasets/VOCdevkit\r\n","#!ln -s /content/valid/ ./datasets/VOCdevkit\r\n","#!ln -s /content/test/ ./datasets/VOCdevkit"],"outputs":[],"metadata":{"id":"gp1L8zdwGo_j"}},{"cell_type":"code","execution_count":null,"source":["%cd SwitchFrequencyAnalysis\r\n","%cd /content/\r\n","\r\n","# copy the datasets zip file to the root darknet folder\r\n","!cp /mydrive/yolox/objx.zip ../\r\n","\r\n","# unzip the datasets and their contents so that they are now in YOLOX/datasets/VOCdevkit/ folder\r\n","!unzip ../objx.zip -d YOLOX/datasets/VOCdevkit/"],"outputs":[],"metadata":{"id":"GDMYvZFJJ_5K"}},{"cell_type":"markdown","source":["## Format Your Data Appropriately"],"metadata":{"id":"agZSFjXLByrv"}},{"cell_type":"code","execution_count":null,"source":["%cd SwitchFrequencyAnalysis\r\n","%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2007\"\r\n","!python3 voc_txt.py \"/content/YOLOX/datasets/VOCdevkit/\""],"outputs":[],"metadata":{"id":"_xTRtDWrIw_D"}},{"cell_type":"markdown","source":["## Change the Classes\n","Make sure you change the classes based on what your dataset. To ensure that the training process will function as intended, write the classes in lowercase with no whitespace."],"metadata":{"id":"BW8iyuMyB3bc"}},{"cell_type":"code","execution_count":null,"source":["from IPython.core.magic import register_line_cell_magic\r\n","\r\n","@register_line_cell_magic\r\n","def writetemplate(line, cell):\r\n","    with open(line, 'w') as f:\r\n","        f.write(cell.format(**globals()))"],"outputs":[],"metadata":{"id":"rohuAE541Nug","executionInfo":{"status":"ok","timestamp":1632176080251,"user_tz":240,"elapsed":248,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}}}},{"cell_type":"code","execution_count":null,"source":["##REPLACE this cell with your classnames stripped of whitespace and lowercase\r\n","%%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py\r\n","\r\n","VOC_CLASSES = (\r\n","  \"human-head\",\r\n","  \"human-body\"\r\n",")"],"outputs":[],"metadata":{"id":"9h5PM8Ft1OjG","executionInfo":{"status":"ok","timestamp":1632176084029,"user_tz":240,"elapsed":808,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}}}},{"cell_type":"code","execution_count":null,"source":["##REPLACE this cell with your classnames stripped of whitespace and lowercase\r\n","'''\r\n","%%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py\r\n","\r\n","COCO_CLASSES = (\r\n","  \"rbc\",\r\n","  \"wbc\",\r\n","  \"platelets\"\r\n",")\r\n","'''"],"outputs":[],"metadata":{"id":"Lu6_LzErQRSU"}},{"cell_type":"markdown","source":["Set the number of classes you have in your dataset in te `NUM_CLASSES` variable"],"metadata":{"id":"2uAaf5AKSE_E"}},{"cell_type":"code","execution_count":null,"source":["NUM_CLASSES = 2\r\n","!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py\""],"outputs":[],"metadata":{"id":"hxA0JmWqwU_M","executionInfo":{"status":"ok","timestamp":1632176095697,"user_tz":240,"elapsed":886,"user":{"displayName":"Matt Release","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07361301444993132966"}}}},{"cell_type":"markdown","source":["# Download Pretrained Weights"],"metadata":{"id":"eiYvw_GGKaro"}},{"cell_type":"code","execution_count":null,"source":["%cd SwitchFrequencyAnalysis\r\n","%cd /content/\r\n","!wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_tiny.onnx\r\n","!wget https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_tiny.pth\r\n","%cd /content/YOLOX/"],"outputs":[],"metadata":{"id":"UsOCh9hRKbIw"}},{"cell_type":"markdown","source":["# Train the Model"],"metadata":{"id":"2TabCpJOCRti"}},{"cell_type":"code","execution_count":null,"source":["%cd SwitchFrequencyAnalysis\r\n","%cd /content/YOLOX/\r\n","!ls\r\n"],"outputs":[],"metadata":{"id":"s5h536amH32Z"}},{"cell_type":"code","execution_count":null,"source":["!python tools/train.py -f exps/example/yolox_voc/yolox_voc_tiny.py -d 1 -b 64 --fp16 -o -c /content/yolox_tiny.pth"],"outputs":[],"metadata":{"id":"qzeQ_yW6R1Bs"}},{"cell_type":"markdown","source":["# Transfer the Model"],"metadata":{"id":"2TabCpJOCRti"}},{"cell_type":"code","execution_count":null,"source":["!python3 tools/export_onnx.py --output-name yolox_tiny.onnx -f exps/example/yolox_voc/yolox_voc_tiny.py --batch-size 1 -c best_ckpt.v2.pth"],"outputs":[],"metadata":{}}]}